{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021-02-23-opgave_kapitel3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqKNAzuVsh_U"
      },
      "source": [
        "# \"Opgave Fast AI 23/02/2021\"\r\n",
        "> \"Dagens opgave\"\r\n",
        "\r\n",
        "- toc:true- branch: master\r\n",
        "- badges: true\r\n",
        "- comments: true\r\n",
        "- author: Oguz Dastan\r\n",
        "- categories: [fastpages, jupyter]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtdxnTE3uEee"
      },
      "source": [
        "# 1. Explain how the \"pixel similarity\" approach to classifying digits works.\r\n",
        "*   Opstil matrix, der repræsenterer billedet, hvert koordinat repræsenterer et pixel.\r\n",
        "*   Man kan nu sammenligne denne matrice med en idéel udgave af det, som man skal klassificere mod, ved at se på, hvor stor forskel der er på den idéelle matrix og billedmatrixen. Forskellen udregnes typisk med root mean square (L2 norm) eller mean of absolute differences(L1 norm). \r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCst1-U-uaJr"
      },
      "source": [
        "# 2. What is a list comprehension? Create one now that selects odd numbers from a list and doubles them.\r\n",
        "\r\n",
        "\r\n",
        "*  \tlist = [f(x) for x in collection]\r\n",
        "*   Listepunkt\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9cEcNzWvSq_",
        "outputId": "c9adee59-3906-49dd-e909-87af82d23c2e"
      },
      "source": [
        "numberList = [1,2,3,7,8,9]\r\n",
        "evenNumbers = [number * 2 for number in numberList if number % 2 != 0]\r\n",
        "evenNumbers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 6, 14, 18]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cPDMLWgue8j"
      },
      "source": [
        "# 1. What is a \"rank-3 tensor\"?\r\n",
        "\r\n",
        "*   •\tEn tensors rank beskriver hvor mange unikke datatyper den tensor indeholder. Dette har ikke noget med størrelsen eller mængden af data at gøre, men hvad dataen beskriver.\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPSB1fC5ue_L"
      },
      "source": [
        "# 4. What are RMSE and L1 norm?\r\n",
        "\r\n",
        "\r\n",
        "* \tRMSE er hvor man beregner forskellen på to datasæt, det gøres ved at tage forskellen altså (a_1 - b_1)^2 og sætter den i anden, så tager man gennemsnittet af det altså af alle værdierne(a_n-b_n)^2 og så tager du kvadratroden af gennemsnittet for ikke at have forskellen repræsenteres som en kvadrat værdi.\r\n",
        "* L1 Norm er hvor man tager den absolutte forskel fra to værdier, og tager gennemsnittet |a_n - b_n|. Tallet vil altid blive positivt, selvom forskellen kan være -150 så vil selve forskellen være 150. Hvis begge tal er negative, ganger man de to tal og tager den positive kvadratrod.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDKvBl0_ufEi"
      },
      "source": [
        "# 5. Create a 3×3 tensor or array containing the numbers from 1 to 9. Double it. Select the bottom-right four numbers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2bX5rHVSuyE",
        "outputId": "8f259a3c-515f-480b-8efe-ccca8fe5f5fe"
      },
      "source": [
        "!pip install -Uqq fastbook\r\n",
        "import fastbook\r\n",
        "fastbook.setup_book()\r\n",
        "\r\n",
        "from fastai.vision.all import *\r\n",
        "from fastbook import *\r\n",
        "\r\n",
        "matplotlib.rc('image', cmap='Greys')\r\n",
        "\r\n",
        "path = untar_data(URLs.MNIST_SAMPLE)\r\n",
        "\r\n",
        "#hide\r\n",
        "Path.BASE_PATH = path\r\n",
        "path.ls()\r\n",
        "\r\n",
        "import torch as torch\r\n",
        "data = [[1,2,3], [4,5,6], [7,8,9]]\r\n",
        "\r\n",
        "tensordata = tensor(data)\r\n",
        "tensordata = tensordata *2\r\n",
        "\r\n",
        "print(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7llUUYMcwwhy",
        "outputId": "adaa6c0d-5d05-46e7-e86a-05ae1e0b44bc"
      },
      "source": [
        "tensordata[1:, 1:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10, 12],\n",
              "        [16, 18]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWUs1PPVufHG"
      },
      "source": [
        "# 6. What is broadcasting?\r\n",
        "\r\n",
        "\r\n",
        "*   Hvis to tensor er af forskellige ranks kan vi bruge broadcasting til at expande den mindre ranket tensor til samme rank som den større tensor. Det er **vigtigt** at forstå PyTorch ikke faktisk kopier billederne til at opnå ranken, men lader som om at tensoren er af den størrelse. Derved undgås der at allokeres hukommelse til det. Dette muliggør at PyTorch kan bruge matematiske funktioner på de 2 tensors / array f.eks. at gange dem eller tage gennemsittet.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJ1U8YstufJq"
      },
      "source": [
        "# 7. Are metrics generally calculated using the training set, or the validation set? Why?\r\n",
        "\r\n",
        "\r\n",
        "*   Validation, fordi man er nødt til at vide hvor god den er til at predicte på ikke set data.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fygM6d2oufMJ"
      },
      "source": [
        "# 8. What is SGD?\r\n",
        "\r\n",
        "\r\n",
        "*   **Stochastic Gradient Descent**. Det er en iterativ måde at optimere vores model via. gradients. Afhængig af vores learning rate, tager vi små skridt mod det bedste fit.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFcaYnurufOk"
      },
      "source": [
        "# 9. What are the seven steps in SGD for machine learning?\r\n",
        "\r\n",
        "\r\n",
        "*   Initialize the parameters\r\n",
        "*   Calculate the predicitions\r\n",
        "*   Calculate the loss\r\n",
        "*   Calculate the gradients\r\n",
        "*   Step the weights\r\n",
        "*   Repeat the Process\r\n",
        "*   Stop\r\n",
        "\r\n",
        "// IMAGE\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rjbv2I5_y3Nk"
      },
      "source": [
        "# 10. How do we initialize the weights in a model?\r\n",
        "\r\n",
        "\r\n",
        "*   Random eller fra en pretrained model\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu3ylZR2zKmD"
      },
      "source": [
        "# 11. What is \"loss\"?\r\n",
        "\r\n",
        "\r\n",
        "*   Mængden af fejl, numeriske værdier for hvor god ens model er\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtPjoea0zRhP"
      },
      "source": [
        "# 12. Why can't we always use a high learning rate?\r\n",
        "\r\n",
        "\r\n",
        "*   Fordi man vil overshoot ens minimale loss eller nogne gange blive værre, da den tager for store skridt.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYUk8QD7ze8G"
      },
      "source": [
        "# 13. What is a \"gradient\"?\r\n",
        "\r\n",
        "\r\n",
        "*   Differentialet (Hældningen), på et specifikt punkt\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7r6ZmhmzlLS"
      },
      "source": [
        "# 14. Why can't we use accuracy as a loss function?\r\n",
        "\r\n",
        "\r\n",
        "*   Fordi accuracy er ikke godt nok til en model. Loss er en bedre repræsentation, matematisk for fejl.\r\n",
        "*   En meget lille ændring i vægt værdierne vil ikke ændre i vores accuracy og derfor ikke bruges som en loss function\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyU1PSCJ0Cc3"
      },
      "source": [
        "# 15. What is the difference between a loss function and a metric?\r\n",
        "\r\n",
        "\r\n",
        "*   Loss function bruges til at justere vægte mens metrics er det vi selv måler på for at se kvaliteten af vores model\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAneBGI40SQs"
      },
      "source": [
        "# 16. What is the function to calculate new weights using a learning rate?\r\n",
        "\r\n",
        "\r\n",
        "*   Backpropagation\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eITI1jYa0Wu2"
      },
      "source": [
        "# 17. What does the backward method do?\r\n",
        "\r\n",
        "\r\n",
        "*   Metoden går baglæns, starter i slutningen, og tilpasser med ændringerne.\r\n",
        "*   Udregner gradienten for hver vægt i hvert lag\r\n",
        "\r\n"
      ]
    }
  ]
}